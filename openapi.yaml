openapi: 3.0.3
info:
  title: LLM Chat Service API
  description: A web service for anonymous chat conversations powered by Groq's LLM
  version: 1.0.0
  contact:
    name: API Support

servers:
  - url: http://localhost:8000
    description: Local development server

paths:
  /health:
    get:
      summary: Health check endpoint
      description: Returns OK if the service is running
      operationId: healthCheck
      tags:
        - Health
      responses:
        '200':
          description: Service is healthy
          content:
            text/plain:
              schema:
                type: string
                example: OK

  /chat:
    post:
      summary: Send a chat message
      description: |
        Send a chat message and receive a response. Supports streaming via SSE or WebSocket.
        The last message in the array must be from the user role.
      operationId: chat
      tags:
        - Chat
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatRequest'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatResponse'
            text/event-stream:
              schema:
                type: string
                description: SSE stream with data: prefix
        '400':
          description: Bad request (validation error)
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '502':
          description: Bad gateway (LLM API error)
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorResponse'

  /metrics:
    get:
      summary: Prometheus metrics
      description: Returns Prometheus metrics in text format
      operationId: metrics
      tags:
        - Metrics
      responses:
        '200':
          description: Metrics data
          content:
            text/plain:
              schema:
                type: string

components:
  schemas:
    Message:
      type: object
      required:
        - role
        - content
      properties:
        role:
          type: string
          enum: [user, assistant]
          description: Message role (case-sensitive)
        content:
          type: string
          description: Message content
          minLength: 1

    ChatRequest:
      type: object
      required:
        - messages
      properties:
        messages:
          type: array
          items:
            $ref: '#/components/schemas/Message'
          minItems: 1
          description: Array of messages (last must be from user)
        stream:
          type: boolean
          default: true
          description: Whether to stream the response

    ChatResponse:
      type: object
      properties:
        response:
          type: string
          description: Full response text (non-streaming)

    ErrorResponse:
      type: object
      properties:
        error:
          type: string
          description: Error message

